{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "streaming_batch_ELT.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaniamv/final-project-edit/blob/main/streaming_batch_ELT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Aplication in Real Time to Read Carris API - group 1 - ELT approach\n",
        "\n",
        "This notebook documents the steps to implement a data pipeline leveraging Google Cloud Platform (GCP), following an **ELT (Extract, Load, Transform)** approach. The pipeline processes data in two stages:\n",
        "\n",
        "\n",
        "1.   *Streaming Ingestion (Extract and Load):*\n",
        "Data is ingested in real-time from a source bucket on GCP (input bucket) and stored in a bronze layer bucket, preserving the raw format for further processing.\n",
        "2.   *Batch Transformation (Transform):*\n",
        "The raw data from the bronze layer is transformed in batches. These transformations clean, standardize, and structure the data, preparing it for analytical use. The transformed data is then stored in the silver layer bucket for downstream consumption.\n",
        "\n",
        "By prioritizing the ELT approach, this pipeline ensures flexibility in processing and allows the raw data to remain available for future transformations, ensuring adaptability to evolving business requirements.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mswj15PSFOZO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Authentication to Google Cloud Platform (GCP)\n",
        "\n"
      ],
      "metadata": {
        "id": "Af0Q2ITZKZTI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nasp9TP3zwaM",
        "outputId": "653db35d-7c8e-4d80-eab8-46bc2e95cb3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Go to the following link in your browser, and complete the sign-in prompts:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fapplicationdefaultauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=qaOEoFAUxZRbBQ8TfypE63jacO2pKG&prompt=consent&token_usage=remote&access_type=offline&code_challenge=7KM99PL4_dcZdGrGArfJh3ydf_-r8lVuBZnuXfoNMxw&code_challenge_method=S256\n",
            "\n",
            "Once finished, enter the verification code provided in your browser: 4/0ASVgi3J4HBTO7INmBkLwQCLAqti9-TduLXYuH9IiCfbWyy8UxLXATSDzZWRW92o2npmcIA\n",
            "\n",
            "Credentials saved to file: [/content/.config/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\u001b[1;33mWARNING:\u001b[0m \n",
            "Cannot find a quota project to add to ADC. You might receive a \"quota exceeded\" or \"API not enabled\" error. Run $ gcloud auth application-default set-quota-project to add a quota project.\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth application-default login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download connector and save it local\n",
        "\n",
        "!wget https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/hadoop3-2.2.7/gcs-connector-hadoop3-2.2.7-shaded.jar -P /usr/local/lib/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSysWUdy0Gxo",
        "outputId": "b19c314a-4220-44bf-92ce-91d91b71759a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-22 22:39:41--  https://repo1.maven.org/maven2/com/google/cloud/bigdataoss/gcs-connector/hadoop3-2.2.7/gcs-connector-hadoop3-2.2.7-shaded.jar\n",
            "Resolving repo1.maven.org (repo1.maven.org)... 199.232.192.209, 199.232.196.209, 2a04:4e42:4c::209, ...\n",
            "Connecting to repo1.maven.org (repo1.maven.org)|199.232.192.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33831577 (32M) [application/java-archive]\n",
            "Saving to: ‘/usr/local/lib/gcs-connector-hadoop3-2.2.7-shaded.jar’\n",
            "\n",
            "gcs-connector-hadoo 100%[===================>]  32.26M   145MB/s    in 0.2s    \n",
            "\n",
            "2025-01-22 22:39:42 (145 MB/s) - ‘/usr/local/lib/gcs-connector-hadoop3-2.2.7-shaded.jar’ saved [33831577/33831577]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "2. Initialize SparkSession and set up the access to GSC\n"
      ],
      "metadata": {
        "id": "GFpic7qmK_70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName('GCS_Spark') \\\n",
        "    .config('spark.jars', '/usr/local/lib/gcs-connector-hadoop3-2.2.7-shaded.jar') \\\n",
        "    .config('spark.hadoop.fs.gs.impl', 'com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# save credentials\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = '/content/.config/application_default_credentials.json'\n",
        "\n",
        "# Config PySpark to access the GCS\n",
        "spark._jsc.hadoopConfiguration().set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
        "spark._jsc.hadoopConfiguration().set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
        "spark._jsc.hadoopConfiguration().set(\"fs.gs.auth.service.account.enable\", \"true\")\n",
        "spark._jsc.hadoopConfiguration().set(\"google.cloud.auth.service.account.json.keyfile\", '/content/.config/application_default_credentials.json')\n"
      ],
      "metadata": {
        "id": "E6bEUtdP0MFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "3. Set up the source schema and initialize the readStream"
      ],
      "metadata": {
        "id": "vwBoK-roLjEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "# create schema\n",
        "vehicle_schema = StructType([StructField('bearing', IntegerType(), True),\n",
        "                             StructField('block_id', StringType(), True),\n",
        "                             StructField('current_status', StringType(), True),\n",
        "                             StructField('id', StringType(), True),\n",
        "                             StructField('lat', FloatType(), True),\n",
        "                             StructField('line_id', StringType(), True),\n",
        "                             StructField('lon', FloatType(), True),\n",
        "                             StructField('pattern_id', StringType(), True),\n",
        "                             StructField('route_id', StringType(), True),\n",
        "                             StructField('schedule_relationship', StringType(), True),\n",
        "                             StructField('shift_id', StringType(), True),\n",
        "                             StructField('speed', FloatType(), True),\n",
        "                             StructField('stop_id', StringType(), True),\n",
        "                             StructField('timestamp', TimestampType(), True),\n",
        "                             StructField('trip_id', StringType(), True)])\n",
        "\n",
        "\n",
        "#readStreaming\n",
        "stream = spark.readStream.format(\"json\").schema(vehicle_schema).load(\"gs://edit-de-project-streaming-data/carris-vehicles\")"
      ],
      "metadata": {
        "id": "IQCjtB690VfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confirm that stream is streaming\n",
        "stream.isStreaming"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9neYDUU7g3t",
        "outputId": "03afda57-f2dc-4c4a-f801-655134130208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "4. Write the stream in a bronze layer (landing zone)\n",
        "* Purpose: Raw data ingestion layer.\n",
        "* Data Characteristics: Raw, unprocessed, and schema-on-read where feasible.\n",
        "* Data Storage: Store data exactly as ingested (in this case JSON format).\n",
        "* Operations: Minimal transformation; only schema enforcement and deduplication."
      ],
      "metadata": {
        "id": "DYrimmWML5p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bronze_layer=\"gs://edit-data-eng-project-group1/datalake/stream/ELT/bronze_layer\"\n",
        "\n",
        "# writeStreaming\n",
        "query = (stream\n",
        "        .writeStream\n",
        "        .outputMode(\"append\")\n",
        "        .option(\"path\", bronze_layer)\n",
        "        .option('checkpointLocation', 'gs://edit-data-eng-project-group1/datalake/stream/ELT/bronze_layer/checkpoint')\n",
        "        .start()\n",
        "\n",
        "        )\n",
        "\n",
        "query.awaitTermination(60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDn8R7UI7VdW",
        "outputId": "e9452588-ef1d-458d-af20-969a1a6a12be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check the status of the query\n",
        "query.status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc1enbxz7jb_",
        "outputId": "b37a70c9-65aa-4134-b7c7-caf5d6ef4314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'message': 'Processing new data',\n",
              " 'isDataAvailable': True,\n",
              " 'isTriggerActive': True}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check if the write streaming is active\n",
        "query.isActive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5l6ZgAL7lv-",
        "outputId": "4b772abf-7ee5-4be7-81e6-7efc25bbc966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query.stop()"
      ],
      "metadata": {
        "id": "2VzNk8pW8aNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "5. Check if the bronze layer received the files and prepare the bronze layer operations (schema enforcement and deduplication)"
      ],
      "metadata": {
        "id": "vj5FWb6YPSM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vehicle_schema = StructType([StructField('bearing', IntegerType(), True),\n",
        "                             StructField('block_id', StringType(), True),\n",
        "                             StructField('current_status', StringType(), True),\n",
        "                             StructField('id', StringType(), True),\n",
        "                             StructField('lat', FloatType(), True),\n",
        "                             StructField('line_id', StringType(), True),\n",
        "                             StructField('lon', FloatType(), True),\n",
        "                             StructField('pattern_id', StringType(), True),\n",
        "                             StructField('route_id', StringType(), True),\n",
        "                             StructField('schedule_relationship', StringType(), True),\n",
        "                             StructField('shift_id', StringType(), True),\n",
        "                             StructField('speed', FloatType(), True),\n",
        "                             StructField('stop_id', StringType(), True),\n",
        "                             StructField('timestamp', TimestampType(), True),\n",
        "                             StructField('trip_id', StringType(), True)])\n",
        "\n",
        "# Read the Parquet files into a DataFrame\n",
        "parquet_df = spark.read.schema(vehicle_schema).parquet(bronze_layer)\n",
        "\n",
        "parquet_df = parquet_df.drop_duplicates()\n",
        "\n",
        "# Show the first few rows\n",
        "parquet_df.show(truncate=False)\n",
        "\n",
        "# Print the schema to understand the data structure\n",
        "parquet_df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPbjFFE7GKlO",
        "outputId": "ae3b1f24-3758-463d-cacd-1090a3fd93e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+--------------+---+---+-------+---+----------+--------+---------------------+--------+-----+-------+---------+-------+\n",
            "|bearing|block_id|current_status|id |lat|line_id|lon|pattern_id|route_id|schedule_relationship|shift_id|speed|stop_id|timestamp|trip_id|\n",
            "+-------+--------+--------------+---+---+-------+---+----------+--------+---------------------+--------+-----+-------+---------+-------+\n",
            "+-------+--------+--------------+---+---+-------+---+----------+--------+---------------------+--------+-----+-------+---------+-------+\n",
            "\n",
            "root\n",
            " |-- bearing: integer (nullable = true)\n",
            " |-- block_id: string (nullable = true)\n",
            " |-- current_status: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- lat: float (nullable = true)\n",
            " |-- line_id: string (nullable = true)\n",
            " |-- lon: float (nullable = true)\n",
            " |-- pattern_id: string (nullable = true)\n",
            " |-- route_id: string (nullable = true)\n",
            " |-- schedule_relationship: string (nullable = true)\n",
            " |-- shift_id: string (nullable = true)\n",
            " |-- speed: float (nullable = true)\n",
            " |-- stop_id: string (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- trip_id: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "6. Ingest to the silver layer\n",
        "* Purpose: Cleaned and enriched data layer.\n",
        "* Data Characteristics: Schema-on-write, normalized/structured, with quality checks applied.\n",
        "* Operations:\n",
        "Filter for getting only the columns required.\n",
        "Joins with reference data (Historical STOPS) for enrichment.\n",
        "Simple calculations and store it in new columns."
      ],
      "metadata": {
        "id": "PmwPNAcC4tm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lag , col, coalesce\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import FloatType\n",
        "import math\n",
        "\n",
        "def haversine_distance(lat1, lon1, lat2, lon2):\n",
        "\n",
        "    if any(x is None for x in [lat1, lon1, lat2, lon2]):\n",
        "        return 0.0\n",
        "    R = 6371  # Earth's radius in kilometers\n",
        "\n",
        "    # Convert latitude and longitude to radians\n",
        "    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
        "\n",
        "    # Calculate differences\n",
        "    dlat = lat2 - lat1\n",
        "    dlon = lon2 - lon1\n",
        "\n",
        "    # Apply Haversine formula\n",
        "    a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
        "    c = 2 * math.asin(math.sqrt(a))\n",
        "\n",
        "    # Calculate distance\n",
        "    distance = R * c\n",
        "\n",
        "    return distance\n",
        "\n",
        "# Register the UDF\n",
        "distance_udf = udf(haversine_distance, FloatType())\n",
        "\n",
        "# Define a window specification\n",
        "windowSpec = Window.partitionBy(\"id\").orderBy(\"timestamp\")\n",
        "\n",
        "#select columns\n",
        "transform = parquet_df.select('id', 'speed', 'timestamp','line_id','route_id','stop_id','lat', 'lon')\n",
        "\n",
        "# Create a new column 'previous_value' using lag\n",
        "transform = transform.withColumn(\"previous_lat\", coalesce(lag(\"lat\", 1).over(windowSpec), col('lat')))\n",
        "transform = transform.withColumn(\"previous_lon\", coalesce(lag(\"lon\", 1).over(windowSpec), col('lon')))\n",
        "\n",
        "# Get the dataset from endpoint STOPS that we need to join to our main dataset\n",
        "df_stops = spark.read.option(\"header\", \"true\").csv('gs://edit-data-eng-project-group1/LandingZone/GTFS/stops.txt')\n",
        "df_stops = df_stops.select('stop_id','stop_lat','stop_lon')\n",
        "df_stops = df_stops.withColumn(\"stop_lat\", df_stops[\"stop_lat\"].cast(\"float\"))\n",
        "df_stops = df_stops.withColumn(\"stop_lon\", df_stops[\"stop_lon\"].cast(\"float\"))\n",
        "\n",
        "# Join and add new calculated columns\n",
        "transform = transform.join(df_stops, on='stop_id', how='left')\n",
        "\n",
        "transform = transform.withColumn(\"distance\", distance_udf(transform[\"previous_lat\"],transform[\"previous_lon\"],transform[\"lat\"],transform[\"lon\"]))\n",
        "transform = transform.withColumn(\"distance_to_stop\", distance_udf(transform[\"lat\"],transform[\"lon\"],transform[\"stop_lat\"],transform[\"stop_lon\"]))\n",
        "\n",
        "transform.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZyhTfrV2Fj-",
        "outputId": "7e583ef3-ab56-4034-fcf2-d9fa8af6b6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+-------------------+-------+--------+---------+---------+------------+------------+---------+---------+------------+----------------+\n",
            "|stop_id|     id|    speed|          timestamp|line_id|route_id|      lat|      lon|previous_lat|previous_lon| stop_lat| stop_lon|    distance|distance_to_stop|\n",
            "+-------+-------+---------+-------------------+-------+--------+---------+---------+------------+------------+---------+---------+------------+----------------+\n",
            "| 030785|41|1100|     15.0|2025-01-03 18:35:39|   1716|  1716_0| 38.72486|  -9.1829|    38.72486|     -9.1829|38.728104|-9.216909|         0.0|       2.9721527|\n",
            "| 030785|41|1100|11.944445|2025-01-03 18:36:31|   1716|  1716_0| 38.72566|-9.191012|    38.72486|     -9.1829|38.728104|-9.216909|   0.7092681|       2.2628906|\n",
            "| 030785|41|1100|15.833333|2025-01-03 18:36:49|   1716|  1716_0|38.725082|-9.193826|    38.72566|   -9.191012|38.728104|-9.216909|   0.2523195|       2.0304399|\n",
            "| 030785|41|1100|4.4444447|2025-01-03 18:37:27|   1716|  1716_0| 38.72312|-9.199276|   38.725082|   -9.193826|38.728104|-9.216909|   0.5206602|       1.6269007|\n",
            "| 030785|41|1100|4.4444447|2025-01-03 18:37:27|   1716|  1716_0| 38.72312|-9.199276|    38.72312|   -9.199276|38.728104|-9.216909|         0.0|       1.6269007|\n",
            "| 030785|41|1100|7.2222223|2025-01-03 18:38:19|   1716|  1716_0|38.722298|-9.201559|    38.72312|   -9.199276|38.728104|-9.216909|  0.21822897|       1.4798766|\n",
            "| 030785|41|1100| 8.333333|2025-01-03 18:39:08|   1716|  1716_0|38.721363|-9.204338|   38.722298|   -9.201559|38.728104|-9.216909|  0.26253292|       1.3232918|\n",
            "| 030785|41|1100| 8.333333|2025-01-03 18:39:08|   1716|  1716_0|38.721363|-9.204338|   38.721363|   -9.204338|38.728104|-9.216909|         0.0|       1.3232918|\n",
            "| 030785|41|1100|14.722222|2025-01-03 18:39:50|   1716|  1716_0|38.721592|-9.209864|   38.721363|   -9.204338|38.728104|-9.216909|  0.48004118|       0.9475539|\n",
            "| 030785|41|1100|12.222222|2025-01-03 18:40:12|   1716|  1716_0|38.723698|-9.211939|   38.721592|   -9.209864|38.728104|-9.216909|  0.29535377|       0.6526457|\n",
            "| 030785|41|1100|12.222222|2025-01-03 18:40:33|   1716|  1716_0|38.723698|-9.211939|   38.723698|   -9.211939|38.728104|-9.216909|         0.0|       0.6526457|\n",
            "| 030785|41|1100|6.9444447|2025-01-03 18:41:24|   1716|  1716_0| 38.72757|-9.212579|   38.723698|   -9.211939|38.728104|-9.216909|   0.4341016|       0.3803305|\n",
            "| 030785|41|1100|1.9444444|2025-01-03 18:42:23|   1716|  1716_0|38.727955|-9.216708|    38.72757|   -9.212579|38.728104|-9.216909|  0.36076343|      0.02404908|\n",
            "| 030785|41|1100|0.2777778|2025-01-03 18:42:25|   1716|  1716_0| 38.72813|-9.216899|   38.727955|   -9.216708|38.728104|-9.216909| 0.025582656|    0.0031055426|\n",
            "| 030785|41|1100|0.8333333|2025-01-03 18:43:09|   1716|  1716_0|38.728134|-9.216944|    38.72813|   -9.216899|38.728104|-9.216909|0.0039112475|     0.004514944|\n",
            "| 030787|41|1100|4.4444447|2025-01-03 18:43:25|   1716|  1716_0|38.728325|-9.217234|   38.728134|   -9.216944|38.732277|-9.222512|   0.0328981|       0.6346395|\n",
            "| 030787|41|1100|      0.0|2025-01-03 18:44:23|   1716|  1716_0|38.732315|-9.222497|   38.728325|   -9.217234|38.732277|-9.222512|    0.636634|      0.00444345|\n",
            "| 030787|41|1100|      0.0|2025-01-03 18:44:54|   1716|  1716_0|  38.7323|-9.222525|   38.732315|   -9.222497|38.732277|-9.222512|0.0029383234|    0.0027629232|\n",
            "| 030533|41|1100| 8.611111|2025-01-03 18:45:05|   1716|  1716_0|38.732407|-9.222666|     38.7323|   -9.222525| 38.73786|-9.228173| 0.017057238|       0.7720928|\n",
            "| 030533|41|1100|14.166667|2025-01-03 18:45:21|   1716|  1716_0|38.733704|-9.224296|   38.732407|   -9.222666| 38.73786|-9.228173|  0.20195305|      0.57174116|\n",
            "+-------+-------+---------+-------------------+-------+--------+---------+---------+------------+------------+---------+---------+------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHMcnk2ADE-l",
        "outputId": "52ccf7e0-91c7-4475-c7c5-6b649e6554ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- stop_id: string (nullable = true)\n",
            " |-- id: string (nullable = true)\n",
            " |-- speed: float (nullable = true)\n",
            " |-- timestamp: timestamp (nullable = true)\n",
            " |-- line_id: string (nullable = true)\n",
            " |-- route_id: string (nullable = true)\n",
            " |-- lat: float (nullable = true)\n",
            " |-- lon: float (nullable = true)\n",
            " |-- previous_lat: float (nullable = true)\n",
            " |-- previous_lon: float (nullable = true)\n",
            " |-- stop_lat: float (nullable = true)\n",
            " |-- stop_lon: float (nullable = true)\n",
            " |-- distance: float (nullable = true)\n",
            " |-- distance_to_stop: float (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform.write.format(\"parquet\").mode(\"overwrite\").save(\"gs://edit-data-eng-project-group1/datalake/stream/ELT/silver_layer\")"
      ],
      "metadata": {
        "id": "xVPnM-jtTsFy",
        "outputId": "cddd13df-bbba-4de6-9263-fba95e94d87d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+-------------------+---------+---------+------------+------------+---------+---------+------------+----------------+\n",
            "|stop_id|     id|    speed|          timestamp|      lat|      lon|previous_lat|previous_lon| stop_lat| stop_lon|    distance|distance_to_stop|\n",
            "+-------+-------+---------+-------------------+---------+---------+------------+------------+---------+---------+------------+----------------+\n",
            "| 030785|41|1100|     15.0|2025-01-03 18:35:39| 38.72486|  -9.1829|    38.72486|     -9.1829|38.728104|-9.216909|         0.0|       2.9721527|\n",
            "| 030785|41|1100|11.944445|2025-01-03 18:36:31| 38.72566|-9.191012|    38.72486|     -9.1829|38.728104|-9.216909|   0.7092681|       2.2628906|\n",
            "| 030785|41|1100|15.833333|2025-01-03 18:36:49|38.725082|-9.193826|    38.72566|   -9.191012|38.728104|-9.216909|   0.2523195|       2.0304399|\n",
            "| 030785|41|1100|4.4444447|2025-01-03 18:37:27| 38.72312|-9.199276|   38.725082|   -9.193826|38.728104|-9.216909|   0.5206602|       1.6269007|\n",
            "| 030785|41|1100|4.4444447|2025-01-03 18:37:27| 38.72312|-9.199276|    38.72312|   -9.199276|38.728104|-9.216909|         0.0|       1.6269007|\n",
            "| 030785|41|1100|7.2222223|2025-01-03 18:38:19|38.722298|-9.201559|    38.72312|   -9.199276|38.728104|-9.216909|  0.21822897|       1.4798766|\n",
            "| 030785|41|1100| 8.333333|2025-01-03 18:39:08|38.721363|-9.204338|   38.722298|   -9.201559|38.728104|-9.216909|  0.26253292|       1.3232918|\n",
            "| 030785|41|1100| 8.333333|2025-01-03 18:39:08|38.721363|-9.204338|   38.721363|   -9.204338|38.728104|-9.216909|         0.0|       1.3232918|\n",
            "| 030785|41|1100|14.722222|2025-01-03 18:39:50|38.721592|-9.209864|   38.721363|   -9.204338|38.728104|-9.216909|  0.48004118|       0.9475539|\n",
            "| 030785|41|1100|12.222222|2025-01-03 18:40:12|38.723698|-9.211939|   38.721592|   -9.209864|38.728104|-9.216909|  0.29535377|       0.6526457|\n",
            "| 030785|41|1100|12.222222|2025-01-03 18:40:33|38.723698|-9.211939|   38.723698|   -9.211939|38.728104|-9.216909|         0.0|       0.6526457|\n",
            "| 030785|41|1100|6.9444447|2025-01-03 18:41:24| 38.72757|-9.212579|   38.723698|   -9.211939|38.728104|-9.216909|   0.4341016|       0.3803305|\n",
            "| 030785|41|1100|1.9444444|2025-01-03 18:42:23|38.727955|-9.216708|    38.72757|   -9.212579|38.728104|-9.216909|  0.36076343|      0.02404908|\n",
            "| 030785|41|1100|0.2777778|2025-01-03 18:42:25| 38.72813|-9.216899|   38.727955|   -9.216708|38.728104|-9.216909| 0.025582656|    0.0031055426|\n",
            "| 030785|41|1100|0.8333333|2025-01-03 18:43:09|38.728134|-9.216944|    38.72813|   -9.216899|38.728104|-9.216909|0.0039112475|     0.004514944|\n",
            "| 030787|41|1100|4.4444447|2025-01-03 18:43:25|38.728325|-9.217234|   38.728134|   -9.216944|38.732277|-9.222512|   0.0328981|       0.6346395|\n",
            "| 030787|41|1100|      0.0|2025-01-03 18:44:23|38.732315|-9.222497|   38.728325|   -9.217234|38.732277|-9.222512|    0.636634|      0.00444345|\n",
            "| 030787|41|1100|      0.0|2025-01-03 18:44:54|  38.7323|-9.222525|   38.732315|   -9.222497|38.732277|-9.222512|0.0029383234|    0.0027629232|\n",
            "| 030533|41|1100| 8.611111|2025-01-03 18:45:05|38.732407|-9.222666|     38.7323|   -9.222525| 38.73786|-9.228173| 0.017057238|       0.7720928|\n",
            "| 030533|41|1100|14.166667|2025-01-03 18:45:21|38.733704|-9.224296|   38.732407|   -9.222666| 38.73786|-9.228173|  0.20195305|      0.57174116|\n",
            "+-------+-------+---------+-------------------+---------+---------+------------+------------+---------+---------+------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "7. Ingest to the gold layer\n",
        "* Purpose: Aggregated data ready for analytics and reporting.\n",
        "* Data Characteristics: Pre-aggregated, aggregated by business logic, optimized for query performance.\n",
        "* Operations: Aggregations, windowed calculations. Metrics computations (e.g., averages, counts, sums)."
      ],
      "metadata": {
        "id": "X2BXLU-FUZcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = spark.read.format(\"parquet\").load(\"gs://edit-data-eng-project-group1/datalake/stream/ELT/silver_layer\")"
      ],
      "metadata": {
        "id": "TxgkpflWUpP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark.sql.functions as F\n",
        "\n",
        "\n",
        "agg = transform.groupBy(\"id\", \"stop_id\", F.window(\"timestamp\", \"2 minutes\")).agg(\n",
        "    F.sum('distance').alias(\"distance_2_min\"),\n",
        "    F.last('distance_to_stop').alias('distance_to_stop')\n",
        "    )\n",
        "\n",
        "agg = agg.withColumn('speed', col('distance_2_min')/(2/60))\n",
        "\n",
        "agg = agg.filter(agg.distance_to_stop.isNotNull() & (agg.distance_to_stop > 0) & (agg.speed.isNotNull()) & (agg.speed > 0)) \\\n",
        "         .withColumn('time_to_stop', (col('distance_to_stop')/col('speed') * 3600))\n",
        "\n",
        "agg = agg.withColumn(\n",
        "    'time_to_stop',\n",
        "    F.from_unixtime(\n",
        "        F.unix_timestamp(F.lit('00:00:00'), 'HH:mm:ss') + col('time_to_stop'),\n",
        "        'HH:mm:ss'\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "agg.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9M7e7N_Cs2y",
        "outputId": "889f66c0-9a4a-4147-b9f8-19927c2b5314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+--------------------+--------------------+----------------+------------------+------------+\n",
            "|     id|stop_id|              window|      distance_2_min|distance_to_stop|             speed|time_to_stop|\n",
            "+-------+-------+--------------------+--------------------+----------------+------------------+------------+\n",
            "|41|1104| 120083|{2025-01-03 19:26...|0.051517192274332047|       0.2787009|1.5455157682299614|    00:10:49|\n",
            "|41|1109| 060041|{2025-01-03 20:52...|  0.4222240149974823|    0.0031869775|12.666720449924469|    00:00:00|\n",
            "|41|1109| 120533|{2025-01-04 00:02...|  0.0678267776966095|      0.41164023| 2.034803330898285|    00:12:08|\n",
            "|41|1109| 121099|{2025-01-04 01:00...| 0.04669193550944328|       1.0875545|1.4007580652832985|    00:46:35|\n",
            "|41|1114| 120157|{2025-01-03 20:48...| 0.43597667291760445|     0.007636943|13.079300187528133|    00:00:02|\n",
            "|41|1114| 121059|{2025-01-03 20:52...|  0.4232720732688904|    0.0060717873|12.698162198066711|    00:00:01|\n",
            "|41|1114| 121298|{2025-01-03 21:14...|  0.7600761950016022|       0.3641889|22.802285850048065|    00:00:57|\n",
            "|41|1117| 120923|{2025-01-03 23:08...|  0.4317595735192299|     0.069170356|12.952787205576897|    00:00:19|\n",
            "|41|1127| 120315|{2025-01-03 19:52...|  0.5643651038408279|      0.13594572| 16.93095311522484|    00:00:28|\n",
            "|41|1132| 030459|{2025-01-03 21:10...| 0.17437878251075745|     0.051369462| 5.231363475322723|    00:00:35|\n",
            "|41|1132| 030458|{2025-01-03 21:12...|  0.2954575642943382|      0.42232755| 8.863726928830147|    00:02:51|\n",
            "|41|1133| 030191|{2025-01-03 19:36...|  0.6019816547632217|    0.0106586935|18.059449642896652|    00:00:02|\n",
            "|41|1145| 120771|{2025-01-03 19:46...|0.036404624581336975|      0.25560707|1.0921387374401093|    00:14:02|\n",
            "|41|1147| 120999|{2025-01-03 19:26...| 0.49298734962940216|    0.0080699315|14.789620488882065|    00:00:01|\n",
            "|41|1147| 170776|{2025-01-03 22:24...|  0.6530161201953888|    0.0034408334|19.590483605861664|    00:00:00|\n",
            "|41|1147| 120932|{2025-01-03 23:12...| 0.46141254901885986|      0.08896582|13.842376470565796|    00:00:23|\n",
            "|41|1147| 121110|{2025-01-04 00:04...|0.044979244470596313|      0.20493504|1.3493773341178894|    00:09:06|\n",
            "|41|1147| 121108|{2025-01-04 00:04...|  0.2378775179386139|      0.24784148| 7.136325538158417|    00:02:05|\n",
            "|41|1148| 170901|{2025-01-03 18:38...| 0.11540468782186508|      0.20654137|3.4621406346559525|    00:03:34|\n",
            "|41|1149| 030479|{2025-01-03 18:54...|  0.1379062980413437|      0.10283893| 4.137188941240311|    00:01:29|\n",
            "+-------+-------+--------------------+--------------------+----------------+------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform.write.format(\"parquet\").mode(\"overwrite\").save(\"gs://edit-data-eng-project-group1/datalake/stream/ELT/gold_layer\")"
      ],
      "metadata": {
        "id": "9Qb3J7ZbU02g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}